---
title: Simple QA System
emoji: ðŸ¤—
colorFrom: blue
colorTo: green
sdk: docker
pinned: false
---

# Simple QA System

This project is a retrieval-augmented generation (RAG) service that answers natural-language questions about member data sourced from a public API.

## Features

- FastAPI `/ask` endpoint that accepts a natural-language question and returns an answer.
- Retrieval layer backed by FAISS + `sentence-transformers/all-MiniLM-L6-v2` embeddings for semantic search.
- Re-ranking layer with `cross-encoder/ms-marco-MiniLM-L6-v2` to improve the relevance of retrieved results.
- Answer generation via Google Gemini (`gemini-2.5-flash-lite`) with instructions to infer concise answers from retrieved context.
- Data ingestion that pulls from the live `/messages` API on demand.
- Vector store caching (`vector_store.pkl`) so embeddings are reused across requests.
- Basic unit tests covering the data source fallback/deduplication logic and vector search behavior.

## API

### `POST /ask`

Accepts a JSON body with a question and returns an answer.

**Request:**

```json
{
  "text": "When is Layla planning her trip to London?"
}
```

**Response:**

```json
{
  "answer": "Layla is planning her trip to London for next month."
}
```

## Local Development

1.  **Clone the repository:**
    ```bash
    git clone <repository-url>
    cd qa-system-aurora
    ```

2.  **Install dependencies:**
    ```bash
    pip3 install -r requirements.txt
    ```

3.  **Run the application:**
    ```bash
    uvicorn app.main:app --reload
    ```
    The application will be available at `http://127.0.0.1:8000`.

4.  **Environment variables:**
    - `GEMINI_API_KEY` â€“ **required**. Google AI Studio key used by `google-generativeai`.
    - `GEMINI_MODEL_NAME` â€“ override the default `gemini-2.5-flash-lite` model.

5.  **Run tests (optional but recommended):**
    ```bash
    python -m unittest
    ```

## Deployment

This application is containerized using Docker, so it can be deployed to any cloud provider that supports containers. Hereâ€™s an example of how to deploy it using Google Cloud Run:

1.  **Build the Docker image:**
    ```bash
    docker build -t qa-system .
    ```

2.  **Tag the image for Google Container Registry (GCR):**
    ```bash
    docker tag qa-system gcr.io/[PROJECT-ID]/qa-system
    ```
    (Replace `[PROJECT-ID]` with your Google Cloud project ID.)

3.  **Push the image to GCR:**
    ```bash
    docker push gcr.io/[PROJECT-ID]/qa-system
    ```

4.  **Deploy to Cloud Run:**
    ```bash
    gcloud run deploy qa-system \
      --image gcr.io/[PROJECT-ID]/qa-system \
      --platform managed \
      --region [REGION] \
      --allow-unauthenticated
    ```
    (Replace `[REGION]` with your desired region, e.g., `us-central1`.)

This will provide a public URL where the service is accessible.

### A Note on Cold Starts

When deploying this service to a serverless platform (like the free tiers of Google Cloud Run, Render, or Fly.io), be aware of the "cold start" behavior. These platforms often use ephemeral filesystems, which means any local files generated by the applicationâ€”including the `vector_store.pkl` cacheâ€”are deleted when the service goes idle.

As a result, the **first request** to the service after a period of inactivity may be slow (potentially 1-2 minutes) because the application needs to rebuild the vector cache from scratch. Subsequent requests will be fast, as they will use the in-memory cache. This is a common and expected trade-off for the convenience and cost-effectiveness of serverless hosting.

## Design Notes (Bonus 1)

Following approaches were considered for building the question-answering logic:

1.  **Simple Keyword Matching:**
    -   **Description:** This approach involves tokenizing the question, removing stopwords, and searching for the remaining keywords in the dataset.
    -   **Pros:** Very simple and fast to implement. No external libraries are needed.
    -   **Cons:** Highly inaccurate. It doesn't understand the context, synonyms, or relationships between words. "How many cars does Vikram have?" and "Who has a car?" might yield the same results.

2.  **NLP with Entity Recognition:**
    -   **Description:** Earlier iterations relied on spaCy's named-entity recognition to extract people/places from the question and match them against the dataset, returning the most relevant message for that entity.
    -   **Pros:** More accurate than keyword matching because it focused on the key entities being discussed; easy to reason about and deploy.
    -   **Cons:** Still limited to surface-level matches, struggled with overlapping names, and couldn't infer answers that required combining multiple messages or reading between the lines.

3.  **Embedding-based RAG (Current Approach):**
    -   **Description:** Each `user_name: message` pair is embedded with `sentence-transformers/all-MiniLM-L6-v2` and indexed in FAISS. At query time we embed the question, retrieve the top `k` messages, re-rank them for relevance with a `cross-encoder`, and feed them (plus instructions to infer concise answers) to Gemini.
    -   **Pros:** Captures semantic similarity beyond surface keywords, supports inference when the answer is implied, and has been extended with a re-ranker to further refine context quality.
    -   **Cons:** Requires GPU/CPU cycles to (re)build the embedding cache, depends on the external Gemini API, and still needs high-quality data for good answers.

## Data Insights (Bonus 2)

During the analysis of the provided data source, the following was observed:

-   **Dataset trends:** The public endpoint contains 3349 entries across 10 members, with many repeated concierge-style requests.
-   **Duplicate Messages:** The dataset contains a notable number of identical messages from the same users. The application's data preparation step now deduplicates these to ensure the vector store remains clean and efficient.
-   **PII Handling:** The messages contain Personally Identifiable Information (PII), including names, contact details, and travel itineraries. This should be handled sensitively. For a production system, a PII detection and redaction pipeline would be a critical addition to protect user privacy.
-   **Unstructured content:** Messages are short free-form utterances, so semantic embeddings (plus the Gemini inference prompt) are necessary to bridge slight wording differences between the question and stored messages.
